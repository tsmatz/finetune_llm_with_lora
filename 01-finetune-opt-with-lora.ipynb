{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857cafc6-da38-4aa7-8afc-63aa626fa7aa",
   "metadata": {},
   "source": [
    "# 01. Finetuning OPT with LoRA\n",
    "\n",
    "Today's popular auto-regressive models - such as, GPT, LLaMA, Falcon, etc - are decoder-only models, in which the output token is predicted by using only input's text (called a prompt).\n",
    "\n",
    "![Decoder-only transformers](./images/auto_regressive_transformer.png)\n",
    "\n",
    "*\"Decoder-only\" model is implemented using layers in the red box.<br>\n",
    "(Diagram from : [Attention Is All You Need](https://arxiv.org/abs/1706.03762))*\n",
    "\n",
    "In this model, the task is differentiated also by using input's text (i.e, prompt).\n",
    "\n",
    "> Note : See [this repository](https://github.com/tsmatz/nlp-tutorials) for intrinsic idea of LLM transformers.\n",
    "\n",
    "In this example, we fine-tune the pre-trained auto-regressive model, Meta's OPT (```facebook/opt-125m```), by applying LoRA (Low-Rank Adaptation) optimization.\n",
    "\n",
    "In this example, I download the pre-trained model from Hugging Face hub, but fine-tune model with regular PyTorch training loop.<br>\n",
    "(Here I don't use Hugging Face Trainer class.)\n",
    "\n",
    "See [Readme](https://github.com/tsmatz/finetune_llm_with_lora) for prerequisite's setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d49acf1-9ad1-4a6c-9312-6785cb3f5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "# model_name = \"facebook/opt-350m\"\n",
    "# model_name = \"facebook/opt-1.3b\"\n",
    "# model_name = \"facebook/opt-6.7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d835e84-a01d-4c33-926b-60d9dd4a7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead383e5-149b-4bfb-9324-3cc639fd398d",
   "metadata": {},
   "source": [
    "## Prepare dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ecbb08-6a74-4623-bfe8-bddba5254e35",
   "metadata": {},
   "source": [
    "In this example, we use dataset used in [official LoRA example](https://github.com/microsoft/LoRA).\n",
    "\n",
    "Download dataset from official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a564f1-f8f3-42a6-b160-bebdbcc3aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-06 03:27:50--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt [following]\n",
      "--2023-10-06 03:27:51--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9624463 (9.2M) [text/plain]\n",
      "Saving to: ‘train.txt’\n",
      "\n",
      "train.txt           100%[===================>]   9.18M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2023-10-06 03:27:51 (248 MB/s) - ‘train.txt’ saved [9624463/9624463]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48464ea-991f-48b2-9166-3323cfd61676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-06 03:27:54--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt [following]\n",
      "--2023-10-06 03:27:54--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1351149 (1.3M) [text/plain]\n",
      "Saving to: ‘test.txt’\n",
      "\n",
      "test.txt            100%[===================>]   1.29M  --.-KB/s    in 0.006s  \n",
      "\n",
      "2023-10-06 03:27:54 (208 MB/s) - ‘test.txt’ saved [1351149/1351149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09472803-8c62-48e0-9a63-b9b9448f16d3",
   "metadata": {},
   "source": [
    "Show the downloaded data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e60596-028f-4c4b-a95d-f74a0ff3b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : The Vaults | Type : pub | price : more than £ 30 | customer rating : 5 out of 5 | near : Café Adriatic||The Vaults pub near Café Adriatic has a 5 star rating . Prices start at £ 30 . \n",
      "name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Café Brazil||Close to Café Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of £ 10.50 . Delicious Pub food . \n",
      "name : The Eagle | Type : coffee shop | food : Japanese | price : less than £ 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King||The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than £ 20 for Japanese food . \n",
      "name : The Mill | Type : coffee shop | food : French | price : £ 20 - 25 | area : riverside | near : The Sorrento||Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at £ 20- £ 25 it is in the riverside area . \n",
      "name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat||For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat . \n"
     ]
    }
   ],
   "source": [
    "!head -n 5 train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5fabe-590c-459b-aa16-4b5a506fb54b",
   "metadata": {},
   "source": [
    "Convert above data into JsonL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7376e0c0-16c9-46f4-ad4c-83d1a677f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import json\n",
    "\n",
    "def format_convert(read_file, write_file):\n",
    "    with open(read_file, \"r\", encoding=\"utf8\") as reader, \\\n",
    "    \t open(write_file, \"w\", encoding=\"utf8\") as writer :\n",
    "    \tfor line in reader:\n",
    "    \t\titems = line.strip().split(\"||\")\n",
    "    \t\tcontext = items[0]\n",
    "    \t\tcompletion = items[1].strip(\"\\n\")\n",
    "    \t\tx = {}\n",
    "    \t\tx[\"context\"] = context\n",
    "    \t\tx[\"completion\"] = completion\n",
    "    \t\twriter.write(json.dumps(x)+\"\\n\")\n",
    "\n",
    "format_convert(\"train.txt\", \"train_formatted.jsonl\")\n",
    "format_convert(\"test.txt\", \"test_formatted.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec952-fe03-475f-9f3e-22237cc9c44b",
   "metadata": {},
   "source": [
    "Show the converted data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3610111-cf34-432f-b953-1b17e41bc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"context\": \"name : The Vaults | Type : pub | price : more than \\u00a3 30 | customer rating : 5 out of 5 | near : Caf\\u00e9 Adriatic\", \"completion\": \"The Vaults pub near Caf\\u00e9 Adriatic has a 5 star rating . Prices start at \\u00a3 30 .\"}\n",
      "\n",
      "{\"context\": \"name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Caf\\u00e9 Brazil\", \"completion\": \"Close to Caf\\u00e9 Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of \\u00a3 10.50 . Delicious Pub food .\"}\n",
      "\n",
      "{\"context\": \"name : The Eagle | Type : coffee shop | food : Japanese | price : less than \\u00a3 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King\", \"completion\": \"The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than \\u00a3 20 for Japanese food .\"}\n",
      "\n",
      "{\"context\": \"name : The Mill | Type : coffee shop | food : French | price : \\u00a3 20 - 25 | area : riverside | near : The Sorrento\", \"completion\": \"Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at \\u00a3 20- \\u00a3 25 it is in the riverside area .\"}\n",
      "\n",
      "{\"context\": \"name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat\", \"completion\": \"For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat .\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_formatted.jsonl\", \"r\") as reader:\n",
    "    for _ in range(5):\n",
    "        print(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631f786-be4b-40cf-89d9-7009c1888821",
   "metadata": {},
   "source": [
    "Load tokenizer from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5433dc0-b5a5-4c01-adb5-3ffa2279eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    fast_tokenizer=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50817c47-a97b-4f80-975b-836859a0a7cf",
   "metadata": {},
   "source": [
    "Set block size, which is used to separate long text for model consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f250929-5703-4b17-9f7b-26340950c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332617b-1e66-4812-ad47-5eaeb52b101b",
   "metadata": {},
   "source": [
    "Create function to convert data. (Later this function is then used in data loader.)<br>\n",
    "In this function,\n",
    "\n",
    "1. Tokenize both contexts and compeletions. : e.g, ```\"This is a pen.\"``` --> ```[1212, 318, 257, 3112, 13]```\n",
    "2. Concatenate context's token and completion's token. (But it's delimited by \"\\n\" between context and completion.) This is used for inputs for LLM.\n",
    "3. Create labels (targets) with inputs. Label is ```input[1:]``` (i.e, shifted right by one element), and is filled by ```-100``` in context's positions. (See below note.)\n",
    "4. Pad tokens to make the length of token become ```block_size```.\n",
    "\n",
    "> Note : Here I set ```-100``` as an ignored index for loss computation, because PyTorch cross-entropy function (```torch.nn.functional.cross_entropy()```) has a property ```ignore_index``` which default value is ```-100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d2fb34-41dd-4bf4-9887-2f5fae39e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "def fill_ignore_label(l, c):\n",
    "    l[:len(c) - 1] = [-100] * (len(c) - 1)\n",
    "    return l\n",
    "\n",
    "def pad_tokens(tokens, max_seq_length, padding_token):\n",
    "    res_tokens = tokens[:max_seq_length]\n",
    "    token_len = len(res_tokens)\n",
    "    res_tokens = res_tokens + \\\n",
    "        [padding_token for _ in range(max_seq_length - token_len)]\n",
    "    return res_tokens\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # tokenize both context and completion respectively\n",
    "    # (context and completion is delimited by \"\\n\")\n",
    "    context_list = list(zip(*batch))[0]\n",
    "    context_list = [c + \"\\n\" for c in context_list]\n",
    "    completion_list = list(zip(*batch))[1]\n",
    "    context_result = tokenizer(context_list)\n",
    "    context_tokens = context_result[\"input_ids\"]\n",
    "    context_masks = context_result[\"attention_mask\"]\n",
    "    completion_result = tokenizer(completion_list)\n",
    "    completion_tokens = completion_result[\"input_ids\"]\n",
    "    completion_masks = completion_result[\"attention_mask\"]\n",
    "    # OPT tokenizer adds the start token in sequence,\n",
    "    # and we then remove it in completion\n",
    "    completion_tokens = [t[1:] for t in completion_tokens]\n",
    "    completion_masks = [t[1:] for t in completion_masks]\n",
    "    # concatenate token\n",
    "    inputs = [i + j for i, j in zip(context_tokens, completion_tokens)]\n",
    "    masks = [i + j for i, j in zip(context_masks, completion_masks)]\n",
    "    # create label\n",
    "    eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "    labels = [t[1:] + [eos_id] for t in inputs]\n",
    "    labels = list(map(fill_ignore_label, labels, context_tokens))\n",
    "    # truncate and pad tokens\n",
    "    inputs = [pad_tokens(t, block_size, 0) for t in inputs] # OPT and GPT-2 doesn't use pad token (instead attn mask is used)\n",
    "    masks = [pad_tokens(t, block_size, 0) for t in masks]\n",
    "    labels = [pad_tokens(t, block_size, -100) for t in labels]\n",
    "    # convert to tensor\n",
    "    inputs = torch.tensor(inputs, dtype=torch.int64).to(device)\n",
    "    masks = torch.tensor(masks, dtype=torch.int64).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "    return inputs, labels, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084d2e9-ef64-47a2-aec9-d24ead1cb38a",
   "metadata": {},
   "source": [
    "Now create PyTorch dataloader with previous function (collator function).\n",
    "\n",
    "> Note : In this example, data is small and we then load all JSON data in memory.<br>\n",
    "> When it's large, load data progressively by implementing custom PyTorch dataset. (See [here](https://github.com/tsmatz/decision-transformer) for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dcd488d-9382-48c6-8a3c-e308182c78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gradient_accumulation_steps = 16\n",
    "\n",
    "data = pd.read_json(\"train_formatted.jsonl\", lines=True)\n",
    "dataloader = DataLoader(\n",
    "    list(zip(data[\"context\"], data[\"completion\"])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba64144-b698-457e-b827-941020456536",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd360d-7bdc-4fd7-9b12-bcf9fe0a8db2",
   "metadata": {},
   "source": [
    "Load model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271181bd-677a-4da9-9e57-2874f5e47bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab764a-d634-40f8-9edb-a01146845233",
   "metadata": {},
   "source": [
    "## Generate text (before fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559efeaf-4b38-4a0c-9be6-eb394221e374",
   "metadata": {},
   "source": [
    "Now run prediction with downloaded model (which is not still fine-tuned).\n",
    "\n",
    "First we create a function to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a0c4fc-e0a7-4bbf-b25a-c335fe61f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input, mask, eos_id, pred_sequence_length):\n",
    "    predicted_last_id = -1\n",
    "    start_token_len = torch.sum(mask).cpu().numpy()\n",
    "    token_len = start_token_len\n",
    "    with torch.no_grad():\n",
    "        while (predicted_last_id != eos_id) and \\\n",
    "              (token_len - start_token_len < pred_sequence_length):\n",
    "            output = model(\n",
    "                input_ids=input,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            predicted_ids = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "            predicted_last_id = predicted_ids[0][token_len - 1]\n",
    "            input[0][token_len] = predicted_last_id\n",
    "            mask[0][token_len] = 1\n",
    "            token_len = torch.sum(mask).cpu().numpy()\n",
    "    return input, token_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936b1a1-ae9f-48a5-80db-691261dda704",
   "metadata": {},
   "source": [
    "Let's test our function and generate text. (Here we stop the text generation when it reaches 15 tokens in prediction.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b7e13f-e8fb-4a9f-90ed-0464463ef569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>Once upon a time, I was a student at the University of California, Berkeley. I was a\n",
      "</s>My name is Clara and I am a student at the University of California, Berkeley. I am a member of\n"
     ]
    }
   ],
   "source": [
    "eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "\n",
    "result = tokenizer(\"Once upon a time,\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))\n",
    "\n",
    "result = tokenizer(\"My name is Clara and I am\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fb60b-c05d-4884-a9bc-92152c94c894",
   "metadata": {},
   "source": [
    "Now we generate text with our test dataset (5 rows).<br>\n",
    "As you can see below, it cannot output the completion well, because it's not still fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495728ef-fbe6-4953-a354-4b7a8bb88798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "</s>name : The Wrestlers | Type : pub | food : Italian | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Wrestlers | Type : pub | food : Italian | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "The Wrestlers is a restaurant in the heart of the city of Raja, India. It is located in the heart of the city of Raj\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : coffee shop | customer rating : 1 out of 5 | family friendly : yes | near : Avalon\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : coffee shop | customer rating : 1 out of 5 | family friendly : yes | near : Avalon\n",
      "\n",
      "The Cricketers is a coffee shop in Avalon, New York. It is located at the corner of Main Street and Main Street. The coffee\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : All Bar One\n",
      "\n",
      "The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre\n",
      "********** input **********\n",
      "</s>name : The Punter | Type : restaurant | food : English | price : high | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Punter | Type : restaurant | food : English | price : high | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "The Punter is a restaurant in Raja, India. It is located in the heart of the Raja district of Rajasthan. It\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly : yes | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly : yes | near : All Bar One\n",
      "\n",
      "The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3138341-e01c-4fae-af78-c61e34967e92",
   "metadata": {},
   "source": [
    "## LoRA (Low-Rank Adaptation)\n",
    "\n",
    "Now we apply LoRA in our downloaded model.\n",
    "\n",
    "[LoRA (Low-Rank Adaptation)](https://arxiv.org/abs/2106.09685) (which is developed by Microsoft Research) is a popular adaptation method for efficient fine-tuning.\n",
    "\n",
    "In a task-specific fine-tuning, the change in weights during model adaptation has a low intrinsic rank.<br>\n",
    "With this hypothesis, we can assume that model's updates ($ \\Delta W $) will be re-written with much smaller low-rank matrices $ B \\cdot A $ as follows.\n",
    "\n",
    "$$ \\displaystyle W_0 x + \\Delta W x = W_0 x + B \\cdot A x $$\n",
    "\n",
    "where\n",
    "\n",
    "- $ W_0 \\in \\mathbb{R}^{d \\times k} $ is a pre-trained weight's matrix (which is frozen).\n",
    "- $ \\Delta W $ is updates.\n",
    "- $ B \\in \\mathbb{R}^{d \\times r}, A \\in \\mathbb{R}^{r \\times k} $ and $ \\verb| rank |\\ r \\ll min(d, k) $\n",
    "\n",
    "![LoRA](./images/lora.png)\n",
    "\n",
    "*From : [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)*\n",
    "\n",
    "In this assumption, we freeze all weights except for $ B $ and $ A $, and train only these low-ranked matrices $ B $ and $ A $.<br>\n",
    "With this manner, you can fine-tune large transformers for a specific task without full-parameter's fine-tuning.\n",
    "\n",
    "This will significantly save the required capacity (GPU memories) for training, and the number of required GPUs can approximately be reduced to one-fourth in the benchmark with GPT-3.\n",
    "\n",
    "For the purpose of your learning, here I manually (from scratch) convert the current model into the model with LoRA.\n",
    "\n",
    "> Note : You can use ```PEFT``` package to be able to get LoRA model with a few lines of code. (Here I don't use this package.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265832d-a736-4d68-80d3-347833d2c590",
   "metadata": {},
   "source": [
    "Before changing our model, first we check the structure of our model.<br>\n",
    "As you can see below (see the result in the cell), the following 6 linear layers are used in a single transformer layer on OPT.\n",
    "\n",
    "- Linear layer to get key\n",
    "- Linear layer to get value\n",
    "- Linear layer to get query\n",
    "- Linear layer for the output of attention\n",
    "- 2 linear layers (feed-forward layer) for the output of a single layer of transformer\n",
    "\n",
    "According to the practice in [paper](https://arxiv.org/abs/2106.09685), LoRA is applied only to query and value projections. In this example, however, we'll convert all these linear layers into LoRA layers.<br>\n",
    "The transformer in OPT-125M has 12 layers and it then has total 6 x 12 = 72 linear layers to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5acb8f62-791a-4fa4-b00c-2666cf34827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e7239-cb8a-46dd-815d-e48e7e49eea4",
   "metadata": {},
   "source": [
    "First we build custom linear layer with LoRA as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77889272-9a93-491b-93cb-b0bed5ce7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class LoRA_Linear(nn.Module):\n",
    "    def __init__(self, weight, bias, lora_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        row, column = weight.shape\n",
    "\n",
    "        # restore Linear\n",
    "        if bias is None:\n",
    "            self.linear = nn.Linear(column, row, bias=False)\n",
    "            self.linear.load_state_dict({\"weight\": weight})\n",
    "        else:\n",
    "            self.linear = nn.Linear(column, row)\n",
    "            self.linear.load_state_dict({\"weight\": weight, \"bias\": bias})\n",
    "\n",
    "        # create LoRA weights (with initialization)\n",
    "        self.lora_right = nn.Parameter(torch.zeros(column, lora_dim))\n",
    "        nn.init.kaiming_uniform_(self.lora_right, a=math.sqrt(5))\n",
    "        self.lora_left = nn.Parameter(torch.zeros(lora_dim, row))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.linear(input)\n",
    "        y = input @ self.lora_right @ self.lora_left\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e2c9d-545e-4bd9-9b0f-eba3fe29a1de",
   "metadata": {},
   "source": [
    "Replace targeting linear layers with LoRA layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf8a748-a3e3-45b8-9c64-252c56abe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_dim = 4\n",
    "\n",
    "# get target module name\n",
    "target_names = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear) and \"decoder.layers.\" in name:\n",
    "        target_names.append(name)\n",
    "\n",
    "# replace each module with LoRA\n",
    "for name in target_names:\n",
    "    name_struct = name.split(\".\")\n",
    "    # get target module\n",
    "    module_list = [model]\n",
    "    for struct in name_struct:\n",
    "        module_list.append(getattr(module_list[-1], struct))\n",
    "    # build LoRA\n",
    "    lora = LoRA_Linear(\n",
    "        weight = module_list[-1].weight,\n",
    "        bias = module_list[-1].bias,\n",
    "        lora_dim = lora_dim,\n",
    "    ).to(device)\n",
    "    # replace\n",
    "    module_list[-2].__setattr__(name_struct[-1], lora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae2df9-fae7-4ecc-8260-80e8e578d951",
   "metadata": {},
   "source": [
    "See how model is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf16b414-b973-40eb-be81-fd2aa3dde439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (v_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (q_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (out_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): LoRA_Linear(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (fc2): LoRA_Linear(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9099c08-f6a6-45f8-939b-cc3ed9415976",
   "metadata": {},
   "source": [
    "Finally, freeze all parameters except for LoRA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d06bba-955b-4806-8ff7-f217252e3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora_right\" in name or \"lora_left\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4469-2827-4f30-9324-711a9feea1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do this when you run adapter fine-tuning on Hugging Face framework\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c7d6f-6c50-4839-88a5-c851caab9ba2",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b875f-36cc-40b8-aaab-1efda68710f3",
   "metadata": {},
   "source": [
    "Now let's start to run fine-tuning.\n",
    "\n",
    "First we build optimizer as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb51298a-2d55-466c-a990-0ea08a247350",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=1e-3,\n",
    "    betas=(0.9, 0.95),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37db1a8-0053-4acc-94ce-89d87c78942e",
   "metadata": {},
   "source": [
    "In this example, we build cosine scheduler for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f95bdf6-4498-4d40-90aa-1267d55f38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "num_update_steps = math.ceil(len(dataloader) / gradient_accumulation_steps)\n",
    "def _get_cosine_schedule(\n",
    "    current_step: int,\n",
    "    num_warmup_steps: int = 0,\n",
    "    num_training_steps: int = num_epochs * num_update_steps\n",
    "):\n",
    "    if current_step < num_warmup_steps:\n",
    "        return 1.0\n",
    "    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=_get_cosine_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9e828-c4fb-493d-a6de-78e03dbf035e",
   "metadata": {},
   "source": [
    "Run fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d22125-830a-4ec6-8417-cdb8a97ec559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 329/329 - loss: 1.5295\n",
      "Epoch 2 329/329 - loss: 1.3322\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "if os.path.exists(\"loss.txt\"):\n",
    "    os.remove(\"loss.txt\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    model.train()\n",
    "    for i, (inputs, labels, masks) in enumerate(dataloader):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(\n",
    "                input_ids=inputs,\n",
    "                attention_mask=masks,\n",
    "            )\n",
    "            loss = F.cross_entropy(outputs.logits.transpose(1,2), labels)\n",
    "            loss.backward()\n",
    "            if ((i + 1) % gradient_accumulation_steps == 0) or \\\n",
    "               (i + 1 == len(dataloader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1} {math.ceil((i + 1) / gradient_accumulation_steps)}/{num_update_steps} - loss: {loss.item() :2.4f}\", end=\"\\r\")\n",
    "\n",
    "        # record loss\n",
    "        with open(\"loss.txt\", \"a\") as f:\n",
    "            f.write(str(loss.item()))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), \"finetuned_opt.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83993d92-d7ed-4a07-8985-cc59bd4e4fef",
   "metadata": {},
   "source": [
    "> Note : Here we save LoRA-enabled model without any changes, but you can also merge the trained LoRA's parameters into the original linear layer's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc086e5-e93f-4264-a8fa-6428f844ac3c",
   "metadata": {},
   "source": [
    "Show loss transition in plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "458d1683-3865-4d76-82a9-3aff0809083b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"loss.txt\")\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809bc9f-4ff6-46c3-9c43-08c6c2694a82",
   "metadata": {},
   "source": [
    "## Generate text with fine-tuned model\n",
    "\n",
    "Again we check results with our test dataset (5 rows).<br>\n",
    "As you can see below, it can output the completion very well, because it's fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b711d0b-3114-4e7e-b89e-8d0ad80adc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "</s>name : The Phoenix | Type : pub | food : French | price : more than £ 30 | customer rating : 5 out of 5 | area : riverside | family friendly : no | near : Crowne Plaza Hotel\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Phoenix | Type : pub | food : French | price : more than £ 30 | customer rating : 5 out of 5 | area : riverside | family friendly : no | near : Crowne Plaza Hotel\n",
      "The Phoenix is a pub that serves French food . It is located near Crowne Plaza Hotel in the riverside area and has a customer rating of 5\n",
      "********** input **********\n",
      "</s>name : Strada | Type : coffee shop | customer rating : 1 out of 5 | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "</s>name : Strada | Type : coffee shop | customer rating : 1 out of 5 | near : All Bar One\n",
      "Strada is a coffee shop near All Bar One . It has a customer rating of 1 out of 5 .</s>\n",
      "********** input **********\n",
      "</s>name : The Waterman | Type : restaurant | food : Indian | price : less than £ 20 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Waterman | Type : restaurant | food : Indian | price : less than £ 20 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Waterman is a restaurant providing Indian food in the less than £ 20 price range . It is located in the city centre . It is near Raj\n",
      "********** input **********\n",
      "</s>name : The Punter | Type : restaurant | food : Italian | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : Rainbow Vegetarian Café\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Punter | Type : restaurant | food : Italian | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : Rainbow Vegetarian Café\n",
      "The Punter is a cheap Italian restaurant in the city centre near Rainbow Vegetarian Café . It has a customer rating of 5 out of 5 and is\n",
      "********** input **********\n",
      "</s>name : The Phoenix | Type : pub | food : Fast food | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Phoenix | Type : pub | food : Fast food | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "The Phoenix is a pub that serves fast food . It is located near Raja Indian Cuisine in the riverside area . It is not family friendly\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c1dd3-4057-497a-83ae-f99b1883697e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
