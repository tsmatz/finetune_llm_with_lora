{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857cafc6-da38-4aa7-8afc-63aa626fa7aa",
   "metadata": {},
   "source": [
    "# 01. Finetuning OPT with LoRA\n",
    "\n",
    "Today's popular auto-regressive models - such as, GPT, LLaMA, Falcon, etc - are decoder-only models, in which the output token is predicted by using only input's text (called a prompt).\n",
    "\n",
    "![Decoder-only transformers](./images/auto_regressive_transformer.png)\n",
    "\n",
    "*\"Decoder-only\" model is implemented using layers in the red box.<br>\n",
    "(Diagram from : [Attention Is All You Need](https://arxiv.org/abs/1706.03762))*\n",
    "\n",
    "In this model, the task is differentiated also by using input's text (i.e, prompt).\n",
    "\n",
    "> Note : See [this repository](https://github.com/tsmatz/nlp-tutorials) for intrinsic idea of LLM transformers.\n",
    "\n",
    "In this example, we fine-tune the pre-trained auto-regressive model, Meta's OPT (```facebook/opt-125m```), by applying LoRA (Low-Rank Adaptation) optimization.\n",
    "\n",
    "In this example, I download the pre-trained model from Hugging Face hub, but fine-tune model with regular PyTorch training loop.<br>\n",
    "(Here I don't use Hugging Face Trainer class.)\n",
    "\n",
    "See [Readme](https://github.com/tsmatz/finetune_llm_with_lora) for prerequisite's setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d49acf1-9ad1-4a6c-9312-6785cb3f5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/opt-125m\"\n",
    "# model_name = \"facebook/opt-350m\"\n",
    "# model_name = \"facebook/opt-1.3b\"\n",
    "# model_name = \"facebook/opt-6.7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d835e84-a01d-4c33-926b-60d9dd4a7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead383e5-149b-4bfb-9324-3cc639fd398d",
   "metadata": {},
   "source": [
    "## Prepare dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ecbb08-6a74-4623-bfe8-bddba5254e35",
   "metadata": {},
   "source": [
    "In this example, we use dataset used in [official LoRA example](https://github.com/microsoft/LoRA).\n",
    "\n",
    "Download dataset from official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a564f1-f8f3-42a6-b160-bebdbcc3aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-06 03:27:50--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt [following]\n",
      "--2023-10-06 03:27:51--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9624463 (9.2M) [text/plain]\n",
      "Saving to: ‘train.txt’\n",
      "\n",
      "train.txt           100%[===================>]   9.18M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2023-10-06 03:27:51 (248 MB/s) - ‘train.txt’ saved [9624463/9624463]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48464ea-991f-48b2-9166-3323cfd61676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-06 03:27:54--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt [following]\n",
      "--2023-10-06 03:27:54--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1351149 (1.3M) [text/plain]\n",
      "Saving to: ‘test.txt’\n",
      "\n",
      "test.txt            100%[===================>]   1.29M  --.-KB/s    in 0.006s  \n",
      "\n",
      "2023-10-06 03:27:54 (208 MB/s) - ‘test.txt’ saved [1351149/1351149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09472803-8c62-48e0-9a63-b9b9448f16d3",
   "metadata": {},
   "source": [
    "Show the downloaded data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e60596-028f-4c4b-a95d-f74a0ff3b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : The Vaults | Type : pub | price : more than £ 30 | customer rating : 5 out of 5 | near : Café Adriatic||The Vaults pub near Café Adriatic has a 5 star rating . Prices start at £ 30 . \n",
      "name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Café Brazil||Close to Café Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of £ 10.50 . Delicious Pub food . \n",
      "name : The Eagle | Type : coffee shop | food : Japanese | price : less than £ 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King||The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than £ 20 for Japanese food . \n",
      "name : The Mill | Type : coffee shop | food : French | price : £ 20 - 25 | area : riverside | near : The Sorrento||Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at £ 20- £ 25 it is in the riverside area . \n",
      "name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat||For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat . \n"
     ]
    }
   ],
   "source": [
    "!head -n 5 train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5fabe-590c-459b-aa16-4b5a506fb54b",
   "metadata": {},
   "source": [
    "Convert above data into JsonL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7376e0c0-16c9-46f4-ad4c-83d1a677f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import json\n",
    "\n",
    "def format_convert(read_file, write_file):\n",
    "    with open(read_file, \"r\", encoding=\"utf8\") as reader, \\\n",
    "    \t open(write_file, \"w\", encoding=\"utf8\") as writer :\n",
    "    \tfor line in reader:\n",
    "    \t\titems = line.strip().split(\"||\")\n",
    "    \t\tcontext = items[0]\n",
    "    \t\tcompletion = items[1].strip(\"\\n\")\n",
    "    \t\tx = {}\n",
    "    \t\tx[\"context\"] = context\n",
    "    \t\tx[\"completion\"] = completion\n",
    "    \t\twriter.write(json.dumps(x)+\"\\n\")\n",
    "\n",
    "format_convert(\"train.txt\", \"train_formatted.jsonl\")\n",
    "format_convert(\"test.txt\", \"test_formatted.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec952-fe03-475f-9f3e-22237cc9c44b",
   "metadata": {},
   "source": [
    "Show the converted data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb32aca7-bd0e-4847-a4c2-cc7e67dc2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"context\": \"name : The Vaults | Type : pub | price : more than \\u00a3 30 | customer rating : 5 out of 5 | near : Caf\\u00e9 Adriatic\", \"completion\": \"The Vaults pub near Caf\\u00e9 Adriatic has a 5 star rating . Prices start at \\u00a3 30 .\"}\n",
      "\n",
      "{\"context\": \"name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Caf\\u00e9 Brazil\", \"completion\": \"Close to Caf\\u00e9 Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of \\u00a3 10.50 . Delicious Pub food .\"}\n",
      "\n",
      "{\"context\": \"name : The Eagle | Type : coffee shop | food : Japanese | price : less than \\u00a3 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King\", \"completion\": \"The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than \\u00a3 20 for Japanese food .\"}\n",
      "\n",
      "{\"context\": \"name : The Mill | Type : coffee shop | food : French | price : \\u00a3 20 - 25 | area : riverside | near : The Sorrento\", \"completion\": \"Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at \\u00a3 20- \\u00a3 25 it is in the riverside area .\"}\n",
      "\n",
      "{\"context\": \"name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat\", \"completion\": \"For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat .\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_formatted.jsonl\", \"r\") as reader:\n",
    "    for _ in range(5):\n",
    "        print(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631f786-be4b-40cf-89d9-7009c1888821",
   "metadata": {},
   "source": [
    "Load tokenizer from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5433dc0-b5a5-4c01-adb5-3ffa2279eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    fast_tokenizer=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50817c47-a97b-4f80-975b-836859a0a7cf",
   "metadata": {},
   "source": [
    "Set block size, which is used to separate long text for model consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f250929-5703-4b17-9f7b-26340950c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332617b-1e66-4812-ad47-5eaeb52b101b",
   "metadata": {},
   "source": [
    "Create function to convert data. (Later this function is then used in data loader.)<br>\n",
    "In this function,\n",
    "\n",
    "1. Tokenize both contexts and compeletions. : e.g, ```\"This is a pen.\"``` --> ```[1212, 318, 257, 3112, 13]```\n",
    "2. Concatenate context's token and completion's token. (But it's delimited by \"\\n\" between context and completion.) This is used for inputs for LLM.\n",
    "3. Create labels (targets) with inputs. Label is ```input[1:]``` (i.e, shifted right by one element), and is filled by ```-100``` in context's positions. (See below note.)\n",
    "4. Pad tokens to make the length of token become ```block_size```.\n",
    "\n",
    "> Note : Here I set ```-100``` as an ignored index for loss computation, because PyTorch cross-entropy function (```torch.nn.functional.cross_entropy()```) has a property ```ignore_index``` which default value is ```-100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2f38aa-b3d0-4614-aa59-8ddd977176d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "def fill_ignore_label(l, c):\n",
    "    l[:len(c) - 1] = [-100] * (len(c) - 1)\n",
    "    return l\n",
    "\n",
    "def pad_tokens(tokens, max_seq_length, padding_token):\n",
    "    res_tokens = tokens[:max_seq_length]\n",
    "    token_len = len(res_tokens)\n",
    "    res_tokens = res_tokens + \\\n",
    "        [padding_token for _ in range(max_seq_length - token_len)]\n",
    "    return res_tokens\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # tokenize both context and completion respectively\n",
    "    # (context and completion is delimited by \"\\n\")\n",
    "    context_list = list(zip(*batch))[0]\n",
    "    context_list = [c + \"\\n\" for c in context_list]\n",
    "    completion_list = list(zip(*batch))[1]\n",
    "    context_result = tokenizer(context_list)\n",
    "    context_tokens = context_result[\"input_ids\"]\n",
    "    context_masks = context_result[\"attention_mask\"]\n",
    "    completion_result = tokenizer(completion_list)\n",
    "    completion_tokens = completion_result[\"input_ids\"]\n",
    "    completion_masks = completion_result[\"attention_mask\"]\n",
    "    # OPT tokenizer adds the start token in sequence,\n",
    "    # and we then remove it in completion\n",
    "    completion_tokens = [t[1:] for t in completion_tokens]\n",
    "    completion_masks = [t[1:] for t in completion_masks]\n",
    "    # concatenate token\n",
    "    inputs = [i + j for i, j in zip(context_tokens, completion_tokens)]\n",
    "    masks = [i + j for i, j in zip(context_masks, completion_masks)]\n",
    "    # create label\n",
    "    eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "    labels = [t[1:] + [eos_id] for t in inputs]\n",
    "    labels = list(map(fill_ignore_label, labels, context_tokens))\n",
    "    # truncate and pad tokens\n",
    "    inputs = [pad_tokens(t, block_size, 0) for t in inputs] # OPT and GPT-2 doesn't use pad token (instead attn mask is used)\n",
    "    masks = [pad_tokens(t, block_size, 0) for t in masks]\n",
    "    labels = [pad_tokens(t, block_size, -100) for t in labels]\n",
    "    # convert to tensor\n",
    "    inputs = torch.tensor(inputs, dtype=torch.int64).to(device)\n",
    "    masks = torch.tensor(masks, dtype=torch.int64).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "    return inputs, labels, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084d2e9-ef64-47a2-aec9-d24ead1cb38a",
   "metadata": {},
   "source": [
    "Now create PyTorch dataloader with previous function (collator function).\n",
    "\n",
    "> Note : In this example, data is small and we then load all JSON data in memory.<br>\n",
    "> When it's large, load data progressively by implementing custom PyTorch dataset. (See [here](https://github.com/tsmatz/decision-transformer) for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bce3bb-2215-4bd6-a6a6-5b6b9d5afdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gradient_accumulation_steps = 16\n",
    "\n",
    "data = pd.read_json(\"train_formatted.jsonl\", lines=True)\n",
    "dataloader = DataLoader(\n",
    "    list(zip(data[\"context\"], data[\"completion\"])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba64144-b698-457e-b827-941020456536",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd360d-7bdc-4fd7-9b12-bcf9fe0a8db2",
   "metadata": {},
   "source": [
    "Load model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271181bd-677a-4da9-9e57-2874f5e47bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab764a-d634-40f8-9edb-a01146845233",
   "metadata": {},
   "source": [
    "## Generate text (before fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559efeaf-4b38-4a0c-9be6-eb394221e374",
   "metadata": {},
   "source": [
    "Now run prediction with downloaded model (which is not still fine-tuned).\n",
    "\n",
    "First we create a function to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a0c4fc-e0a7-4bbf-b25a-c335fe61f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input, mask, eos_id, pred_sequence_length):\n",
    "    predicted_last_id = -1\n",
    "    start_token_len = torch.sum(mask).cpu().numpy()\n",
    "    token_len = start_token_len\n",
    "    with torch.no_grad():\n",
    "        while (predicted_last_id != eos_id) and \\\n",
    "              (token_len - start_token_len < pred_sequence_length):\n",
    "            output = model(\n",
    "                input_ids=input,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            predicted_ids = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "            predicted_last_id = predicted_ids[0][token_len - 1]\n",
    "            input[0][token_len] = predicted_last_id\n",
    "            mask[0][token_len] = 1\n",
    "            token_len = torch.sum(mask).cpu().numpy()\n",
    "    return input, token_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936b1a1-ae9f-48a5-80db-691261dda704",
   "metadata": {},
   "source": [
    "Let's test our function and generate text. (Here we stop the text generation when it reaches 15 tokens in prediction.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b7e13f-e8fb-4a9f-90ed-0464463ef569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>Once upon a time, I was a student at the University of California, Berkeley. I was a\n",
      "</s>My name is Clara and I am a student at the University of California, Berkeley. I am a member of\n"
     ]
    }
   ],
   "source": [
    "eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "\n",
    "result = tokenizer(\"Once upon a time,\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))\n",
    "\n",
    "result = tokenizer(\"My name is Clara and I am\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fb60b-c05d-4884-a9bc-92152c94c894",
   "metadata": {},
   "source": [
    "Now we generate text with our test dataset (5 rows).<br>\n",
    "As you can see below, it cannot output the completion well, because it's not still fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495728ef-fbe6-4953-a354-4b7a8bb88798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "</s>name : The Wrestlers | Type : pub | food : Italian | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Wrestlers | Type : pub | food : Italian | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "The Wrestlers is a restaurant in the heart of the city of Raja, India. It is located in the heart of the city of Raj\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : coffee shop | customer rating : 1 out of 5 | family friendly : yes | near : Avalon\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : coffee shop | customer rating : 1 out of 5 | family friendly : yes | near : Avalon\n",
      "\n",
      "The Cricketers is a coffee shop in Avalon, New York. It is located at the corner of Main Street and Main Street. The coffee\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : All Bar One\n",
      "\n",
      "The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre\n",
      "********** input **********\n",
      "</s>name : The Punter | Type : restaurant | food : English | price : high | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Punter | Type : restaurant | food : English | price : high | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "The Punter is a restaurant in Raja, India. It is located in the heart of the Raja district of Rajasthan. It\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly : yes | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly : yes | near : All Bar One\n",
      "\n",
      "The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3138341-e01c-4fae-af78-c61e34967e92",
   "metadata": {},
   "source": [
    "## LoRA (Low-Rank Adaptation)\n",
    "\n",
    "Now we apply LoRA in our downloaded model.\n",
    "\n",
    "[LoRA (Low-Rank Adaptation)](https://arxiv.org/abs/2106.09685) (which is developed by Microsoft Research) is a popular adaptation method for efficient fine-tuning.\n",
    "\n",
    "In a task-specific fine-tuning, the change in weights during model adaptation has a low intrinsic rank.<br>\n",
    "With this hypothesis, we can assume that model's updates ($ \\Delta W $) will be re-written with much smaller low-rank matrices $ B \\cdot A $ as follows.\n",
    "\n",
    "$$ \\displaystyle W_0 x + \\Delta W x = W_0 x + B \\cdot A x $$\n",
    "\n",
    "where\n",
    "\n",
    "- $ W_0 \\in \\mathbb{R}^{d \\times k} $ is a pre-trained weight's matrix (which is frozen).\n",
    "- $ \\Delta W $ is updates.\n",
    "- $ B \\in \\mathbb{R}^{d \\times r}, A \\in \\mathbb{R}^{r \\times k} $ and $ \\verb| rank |\\ r \\ll min(d, k) $\n",
    "\n",
    "![LoRA](./images/lora.png)\n",
    "\n",
    "*From : [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)*\n",
    "\n",
    "In this assumption, we freeze all weights except for $ B $ and $ A $, and train only these low-ranked matrices $ B $ and $ A $.<br>\n",
    "With this manner, you can fine-tune large transformers for a specific task without full-parameter's fine-tuning.\n",
    "\n",
    "This will significantly save the required capacity (GPU memories) for training, and the number of required GPUs can approximately be reduced to one-fourth in the benchmark with GPT-3.\n",
    "\n",
    "For the purpose of your learning, here I manually (from scratch) convert the current model into the model with LoRA.\n",
    "\n",
    "> Note : You can use ```PEFT``` package to be able to get LoRA model with a few lines of code. (Here I don't use this package.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265832d-a736-4d68-80d3-347833d2c590",
   "metadata": {},
   "source": [
    "Before changing our model, first we check the structure of our model.<br>\n",
    "As you can see below (see the result in the cell), the following 6 linear layers are used in a single transformer layer on OPT.\n",
    "\n",
    "- Linear layer to get key\n",
    "- Linear layer to get value\n",
    "- Linear layer to get query\n",
    "- Linear layer for the output of attention\n",
    "- 2 linear layers (feed-forward layer) for the output of a single layer of transformer\n",
    "\n",
    "In this example, we'll convert all these layers into LoRA layers.<br>\n",
    "The transformer in OPT-125M has 12 layers and it then has total 6 x 12 = 72 linear layers to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5acb8f62-791a-4fa4-b00c-2666cf34827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e7239-cb8a-46dd-815d-e48e7e49eea4",
   "metadata": {},
   "source": [
    "First we build custom linear layer with LoRA as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77889272-9a93-491b-93cb-b0bed5ce7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class LoRA_Linear(nn.Module):\n",
    "    def __init__(self, weight, bias, lora_dim):\n",
    "        super(LoRA_Linear, self).__init__()\n",
    "\n",
    "        row, column = weight.shape\n",
    "\n",
    "        # restore Linear\n",
    "        if bias is None:\n",
    "            self.linear = nn.Linear(column, row, bias=False)\n",
    "            self.linear.load_state_dict({\"weight\": weight})\n",
    "        else:\n",
    "            self.linear = nn.Linear(column, row)\n",
    "            self.linear.load_state_dict({\"weight\": weight, \"bias\": bias})\n",
    "\n",
    "        # create LoRA weights (with initialization)\n",
    "        self.lora_right = nn.Parameter(torch.zeros(column, lora_dim))\n",
    "        nn.init.kaiming_uniform_(self.lora_right, a=math.sqrt(5))\n",
    "        self.lora_left = nn.Parameter(torch.zeros(lora_dim, row))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.linear(input)\n",
    "        y = input @ self.lora_right @ self.lora_left\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e2c9d-545e-4bd9-9b0f-eba3fe29a1de",
   "metadata": {},
   "source": [
    "Replace targeting linear layers with LoRA layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf8a748-a3e3-45b8-9c64-252c56abe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_dim = 128\n",
    "\n",
    "# get target module name\n",
    "target_names = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear) and \"decoder.layers.\" in name:\n",
    "        target_names.append(name)\n",
    "\n",
    "# replace each module with LoRA\n",
    "for name in target_names:\n",
    "    name_struct = name.split(\".\")\n",
    "    # get target module\n",
    "    module_list = [model]\n",
    "    for struct in name_struct:\n",
    "        module_list.append(getattr(module_list[-1], struct))\n",
    "    # build LoRA\n",
    "    lora = LoRA_Linear(\n",
    "        weight = module_list[-1].weight,\n",
    "        bias = module_list[-1].bias,\n",
    "        lora_dim = lora_dim,\n",
    "    ).to(device)\n",
    "    # replace\n",
    "    module_list[-2].__setattr__(name_struct[-1], lora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae2df9-fae7-4ecc-8260-80e8e578d951",
   "metadata": {},
   "source": [
    "See how model is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf16b414-b973-40eb-be81-fd2aa3dde439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (v_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (q_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (out_proj): LoRA_Linear(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): LoRA_Linear(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (fc2): LoRA_Linear(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9099c08-f6a6-45f8-939b-cc3ed9415976",
   "metadata": {},
   "source": [
    "Finally, freeze all parameters except for LoRA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d06bba-955b-4806-8ff7-f217252e3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora_right\" in name or \"lora_left\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4469-2827-4f30-9324-711a9feea1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do this when you run adapter fine-tuning on Hugging Face framework\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c7d6f-6c50-4839-88a5-c851caab9ba2",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b875f-36cc-40b8-aaab-1efda68710f3",
   "metadata": {},
   "source": [
    "Now let's start to run fine-tuning.\n",
    "\n",
    "First we build optimizer as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb51298a-2d55-466c-a990-0ea08a247350",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=1e-3,\n",
    "    betas=(0.9, 0.95),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37db1a8-0053-4acc-94ce-89d87c78942e",
   "metadata": {},
   "source": [
    "In this example, we build cosine scheduler for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f95bdf6-4498-4d40-90aa-1267d55f38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "num_update_steps = math.ceil(len(dataloader) / batch_size / gradient_accumulation_steps)\n",
    "def _get_cosine_schedule(\n",
    "    current_step: int,\n",
    "    num_warmup_steps: int = 0,\n",
    "    num_training_steps: int = num_epochs * num_update_steps\n",
    "):\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=_get_cosine_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9e828-c4fb-493d-a6de-78e03dbf035e",
   "metadata": {},
   "source": [
    "Run fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75d22125-830a-4ec6-8417-cdb8a97ec559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 42/42 - loss: 1.0724\n",
      "Epoch 2 42/42 - loss: 1.3185\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "if os.path.exists(\"loss.txt\"):\n",
    "    os.remove(\"loss.txt\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    model.train()\n",
    "    for i, (inputs, labels, masks) in enumerate(dataloader):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(\n",
    "                input_ids=inputs,\n",
    "                attention_mask=masks,\n",
    "            )\n",
    "            loss = F.cross_entropy(outputs.logits.transpose(1,2), labels)\n",
    "            loss.backward()\n",
    "            if ((i + 1) % gradient_accumulation_steps == 0) or \\\n",
    "               (i + 1 == len(dataloader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1} {math.ceil((i + 1) / batch_size / gradient_accumulation_steps)}/{num_update_steps} - loss: {loss.item() :2.4f}\", end=\"\\r\")\n",
    "\n",
    "        # record loss\n",
    "        with open(\"loss.txt\", \"a\") as f:\n",
    "            f.write(str(loss.item()))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), \"finetuned_opt.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83993d92-d7ed-4a07-8985-cc59bd4e4fef",
   "metadata": {},
   "source": [
    "> Note : Here we save LoRA-enabled model without any changes, but you can also merge the trained LoRA's parameters into the original linear layer's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc086e5-e93f-4264-a8fa-6428f844ac3c",
   "metadata": {},
   "source": [
    "Show loss transition in plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37c5aee-38d4-4a2a-952c-4fd2bef41e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"loss.txt\")\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809bc9f-4ff6-46c3-9c43-08c6c2694a82",
   "metadata": {},
   "source": [
    "## Generate text with fine-tuned model\n",
    "\n",
    "Again we check results with our test dataset (5 rows).<br>\n",
    "As you can see below, it can output the completion very well, because it's fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29903cae-404e-4209-9c84-6c8a69609c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "</s>name : The Punter | Type : pub | food : Chinese | price : more than £ 30 | area : riverside | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Punter | Type : pub | food : Chinese | price : more than £ 30 | area : riverside | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Punter is a children friendly pub that serves Chinese food. It is located in the riverside area near Raja Indian Cuisine and has a\n",
      "********** input **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : no | near : All Bar One\n",
      "The Cricketers is a Chinese restaurant with a cheap price range, located in the city centre near All Bar One. It has a customer rating of\n",
      "********** input **********\n",
      "</s>name : The Phoenix | Type : pub | food : French | price : moderate | customer rating : 1 out of 5 | area : riverside | family friendly : no | near : Crowne Plaza Hotel\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Phoenix | Type : pub | food : French | price : moderate | customer rating : 1 out of 5 | area : riverside | family friendly : no | near : Crowne Plaza Hotel\n",
      "The Phoenix is a pub that serves French food. It is located near Crown Plaza Hotel in the riverside area. It has a moderate price range and\n",
      "********** input **********\n",
      "</s>name : Giraffe | Type : restaurant | food : Fast food | area : riverside | family friendly : yes | near : Rainbow Vegetarian Café\n",
      "\n",
      "********** result **********\n",
      "</s>name : Giraffe | Type : restaurant | food : Fast food | area : riverside | family friendly : yes | near : Rainbow Vegetarian Café\n",
      "Giraffe is a fast food restaurant located in the riverside area near Rainbow Vegetarian Café. It is family friendly.</s>\n",
      "********** input **********\n",
      "</s>name : The Vaults | Type : pub | food : French | price : more than £ 30 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "</s>name : The Vaults | Type : pub | food : French | price : more than £ 30 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Vaults is a children friendly French pub located in the city centre near Raja Indian Cuisine.</s>\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c1dd3-4057-497a-83ae-f99b1883697e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
