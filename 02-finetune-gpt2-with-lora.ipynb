{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857cafc6-da38-4aa7-8afc-63aa626fa7aa",
   "metadata": {},
   "source": [
    "# 02. Finetuning GPT-2 with LoRA\n",
    "\n",
    "In this example, we fine-tune the pre-trained auto-regressive model, **OpenAI's GPT-2** (small version, 124M parameters), by applying LoRA (Low-Rank Adaptation) optimization.\n",
    "\n",
    "In this example, I download the pre-trained model from Hugging Face hub, but fine-tune model with regular PyTorch training loop.<br>\n",
    "(Here I don't use Hugging Face Trainer class.)\n",
    "\n",
    "See [Readme](https://github.com/tsmatz/finetune_llm_with_lora) for prerequisite's setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d49acf1-9ad1-4a6c-9312-6785cb3f5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d835e84-a01d-4c33-926b-60d9dd4a7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead383e5-149b-4bfb-9324-3cc639fd398d",
   "metadata": {},
   "source": [
    "## Prepare dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ecbb08-6a74-4623-bfe8-bddba5254e35",
   "metadata": {},
   "source": [
    "In this example, we use dataset used in [official LoRA example](https://github.com/microsoft/LoRA).\n",
    "\n",
    "Download dataset from official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a564f1-f8f3-42a6-b160-bebdbcc3aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-06 03:27:50--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt [following]\n",
      "--2023-10-06 03:27:51--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9624463 (9.2M) [text/plain]\n",
      "Saving to: ‘train.txt’\n",
      "\n",
      "train.txt           100%[===================>]   9.18M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2023-10-06 03:27:51 (248 MB/s) - ‘train.txt’ saved [9624463/9624463]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48464ea-991f-48b2-9166-3323cfd61676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-06 03:27:54--  https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt [following]\n",
      "--2023-10-06 03:27:54--  https://raw.githubusercontent.com/microsoft/LoRA/main/examples/NLG/data/e2e/test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1351149 (1.3M) [text/plain]\n",
      "Saving to: ‘test.txt’\n",
      "\n",
      "test.txt            100%[===================>]   1.29M  --.-KB/s    in 0.006s  \n",
      "\n",
      "2023-10-06 03:27:54 (208 MB/s) - ‘test.txt’ saved [1351149/1351149]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/microsoft/LoRA/raw/main/examples/NLG/data/e2e/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09472803-8c62-48e0-9a63-b9b9448f16d3",
   "metadata": {},
   "source": [
    "Show the downloaded data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e60596-028f-4c4b-a95d-f74a0ff3b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name : The Vaults | Type : pub | price : more than £ 30 | customer rating : 5 out of 5 | near : Café Adriatic||The Vaults pub near Café Adriatic has a 5 star rating . Prices start at £ 30 . \n",
      "name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Café Brazil||Close to Café Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of £ 10.50 . Delicious Pub food . \n",
      "name : The Eagle | Type : coffee shop | food : Japanese | price : less than £ 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King||The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than £ 20 for Japanese food . \n",
      "name : The Mill | Type : coffee shop | food : French | price : £ 20 - 25 | area : riverside | near : The Sorrento||Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at £ 20- £ 25 it is in the riverside area . \n",
      "name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat||For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat . \n"
     ]
    }
   ],
   "source": [
    "!head -n 5 train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5fabe-590c-459b-aa16-4b5a506fb54b",
   "metadata": {},
   "source": [
    "Convert above data into JsonL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7376e0c0-16c9-46f4-ad4c-83d1a677f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import json\n",
    "\n",
    "def format_convert(read_file, write_file):\n",
    "    with open(read_file, \"r\", encoding=\"utf8\") as reader, \\\n",
    "    \t open(write_file, \"w\", encoding=\"utf8\") as writer :\n",
    "    \tfor line in reader:\n",
    "    \t\titems = line.strip().split(\"||\")\n",
    "    \t\tcontext = items[0]\n",
    "    \t\tcompletion = items[1].strip(\"\\n\")\n",
    "    \t\tx = {}\n",
    "    \t\tx[\"context\"] = context\n",
    "    \t\tx[\"completion\"] = completion\n",
    "    \t\twriter.write(json.dumps(x)+\"\\n\")\n",
    "\n",
    "format_convert(\"train.txt\", \"train_formatted.jsonl\")\n",
    "format_convert(\"test.txt\", \"test_formatted.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec952-fe03-475f-9f3e-22237cc9c44b",
   "metadata": {},
   "source": [
    "Show the converted data (first 5 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb32aca7-bd0e-4847-a4c2-cc7e67dc2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"context\": \"name : The Vaults | Type : pub | price : more than \\u00a3 30 | customer rating : 5 out of 5 | near : Caf\\u00e9 Adriatic\", \"completion\": \"The Vaults pub near Caf\\u00e9 Adriatic has a 5 star rating . Prices start at \\u00a3 30 .\"}\n",
      "\n",
      "{\"context\": \"name : The Cambridge Blue | Type : pub | food : English | price : cheap | near : Caf\\u00e9 Brazil\", \"completion\": \"Close to Caf\\u00e9 Brazil , The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of \\u00a3 10.50 . Delicious Pub food .\"}\n",
      "\n",
      "{\"context\": \"name : The Eagle | Type : coffee shop | food : Japanese | price : less than \\u00a3 20 | customer rating : low | area : riverside | family friendly : yes | near : Burger King\", \"completion\": \"The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than \\u00a3 20 for Japanese food .\"}\n",
      "\n",
      "{\"context\": \"name : The Mill | Type : coffee shop | food : French | price : \\u00a3 20 - 25 | area : riverside | near : The Sorrento\", \"completion\": \"Located near The Sorrento is a French Theme eatery and coffee shop called The Mill , with a price range at \\u00a3 20- \\u00a3 25 it is in the riverside area .\"}\n",
      "\n",
      "{\"context\": \"name : Loch Fyne | food : French | customer rating : high | area : riverside | near : The Rice Boat\", \"completion\": \"For luxurious French food , the Loch Fyne is located by the river next to The Rice Boat .\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"train_formatted.jsonl\", \"r\") as reader:\n",
    "    for _ in range(5):\n",
    "        print(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6631f786-be4b-40cf-89d9-7009c1888821",
   "metadata": {},
   "source": [
    "Load tokenizer from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5433dc0-b5a5-4c01-adb5-3ffa2279eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    fast_tokenizer=True)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50817c47-a97b-4f80-975b-836859a0a7cf",
   "metadata": {},
   "source": [
    "Set block size which is used to separate long text for model consumption.<br>\n",
    "Max 1024 tokens can be used in GPT-2, but here I set 512, because it's enough for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f250929-5703-4b17-9f7b-26340950c055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of tokens is 1024 in this model.\n",
      "But here we use max 512 tokens in the training.\n"
     ]
    }
   ],
   "source": [
    "block_size = 512\n",
    "\n",
    "print(f\"Max length of tokens is {tokenizer.model_max_length} in this model.\")\n",
    "print(f\"But here we use max {block_size} tokens in the training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332617b-1e66-4812-ad47-5eaeb52b101b",
   "metadata": {},
   "source": [
    "Create function to convert data. (Later this function is then used in data loader.)<br>\n",
    "In this function,\n",
    "\n",
    "1. Tokenize both contexts and compeletions. : e.g, ```\"This is a pen.\"``` --> ```[1212, 318, 257, 3112, 13]```\n",
    "2. Concatenate context's token and completion's token. (But it's delimited by \"\\n\" between context and completion.) This is used for inputs for LLM.\n",
    "3. Create labels (targets) with inputs. Label is ```input[1:]``` (i.e, shifted right by one element), and is filled by ```-100``` in context's positions. (See below note.)\n",
    "4. Pad tokens to make the length of token become ```block_size```.\n",
    "\n",
    "> Note : Here I set ```-100``` as an ignored index for loss computation, because PyTorch cross-entropy function (```torch.nn.functional.cross_entropy()```) has a property ```ignore_index``` which default value is ```-100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2f38aa-b3d0-4614-aa59-8ddd977176d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "def fill_ignore_label(l, c):\n",
    "    l[:len(c) - 1] = [-100] * (len(c) - 1)\n",
    "    return l\n",
    "\n",
    "def pad_tokens(tokens, max_seq_length, padding_token):\n",
    "    res_tokens = tokens[:max_seq_length]\n",
    "    token_len = len(res_tokens)\n",
    "    res_tokens = res_tokens + \\\n",
    "        [padding_token for _ in range(max_seq_length - token_len)]\n",
    "    return res_tokens\n",
    "\n",
    "def collate_batch(batch):\n",
    "    # tokenize both context and completion respectively\n",
    "    # (context and completion is delimited by \"\\n\")\n",
    "    context_list = list(zip(*batch))[0]\n",
    "    context_list = [c + \"\\n\" for c in context_list]\n",
    "    completion_list = list(zip(*batch))[1]\n",
    "    context_result = tokenizer(context_list)\n",
    "    context_tokens = context_result[\"input_ids\"]\n",
    "    context_masks = context_result[\"attention_mask\"]\n",
    "    completion_result = tokenizer(completion_list)\n",
    "    completion_tokens = completion_result[\"input_ids\"]\n",
    "    completion_masks = completion_result[\"attention_mask\"]\n",
    "    # concatenate token\n",
    "    inputs = [i + j for i, j in zip(context_tokens, completion_tokens)]\n",
    "    masks = [i + j for i, j in zip(context_masks, completion_masks)]\n",
    "    # create label\n",
    "    eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "    labels = [t[1:] + [eos_id] for t in inputs]\n",
    "    labels = list(map(fill_ignore_label, labels, context_tokens))\n",
    "    # truncate and pad tokens\n",
    "    inputs = [pad_tokens(t, block_size, 0) for t in inputs] # OPT and GPT-2 doesn't use pad token (instead attn mask is used)\n",
    "    masks = [pad_tokens(t, block_size, 0) for t in masks]\n",
    "    labels = [pad_tokens(t, block_size, -100) for t in labels]\n",
    "    # convert to tensor\n",
    "    inputs = torch.tensor(inputs, dtype=torch.int64).to(device)\n",
    "    masks = torch.tensor(masks, dtype=torch.int64).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "    return inputs, labels, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084d2e9-ef64-47a2-aec9-d24ead1cb38a",
   "metadata": {},
   "source": [
    "Now create PyTorch dataloader with previous function (collator function).\n",
    "\n",
    "> Note : In this example, data is small and we then load all JSON data in memory.<br>\n",
    "> When it's large, load data progressively by implementing custom PyTorch dataset. (See [here](https://github.com/tsmatz/decision-transformer) for example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bce3bb-2215-4bd6-a6a6-5b6b9d5afdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "gradient_accumulation_steps = 16\n",
    "\n",
    "data = pd.read_json(\"train_formatted.jsonl\", lines=True)\n",
    "dataloader = DataLoader(\n",
    "    list(zip(data[\"context\"], data[\"completion\"])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba64144-b698-457e-b827-941020456536",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd360d-7bdc-4fd7-9b12-bcf9fe0a8db2",
   "metadata": {},
   "source": [
    "Load model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271181bd-677a-4da9-9e57-2874f5e47bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab764a-d634-40f8-9edb-a01146845233",
   "metadata": {},
   "source": [
    "## Generate text (before fine-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559efeaf-4b38-4a0c-9be6-eb394221e374",
   "metadata": {},
   "source": [
    "Now run prediction with downloaded model (which is not still fine-tuned).\n",
    "\n",
    "First we create a function to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a0c4fc-e0a7-4bbf-b25a-c335fe61f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, input, mask, eos_id, pred_sequence_length):\n",
    "    predicted_last_id = -1\n",
    "    start_token_len = torch.sum(mask).cpu().numpy()\n",
    "    token_len = start_token_len\n",
    "    with torch.no_grad():\n",
    "        while (predicted_last_id != eos_id) and \\\n",
    "              (token_len - start_token_len < pred_sequence_length):\n",
    "            output = model(\n",
    "                input_ids=input,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            predicted_ids = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "            predicted_last_id = predicted_ids[0][token_len - 1]\n",
    "            input[0][token_len] = predicted_last_id\n",
    "            mask[0][token_len] = 1\n",
    "            token_len = torch.sum(mask).cpu().numpy()\n",
    "    return input, token_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936b1a1-ae9f-48a5-80db-691261dda704",
   "metadata": {},
   "source": [
    "Let's test our function and generate text. (Here we stop the text generation when it reaches 15 tokens in prediction.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b7e13f-e8fb-4a9f-90ed-0464463ef569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, the world was a place of great beauty and great danger. The world was\n",
      "My name is Clara and I am a woman. I am a woman who is a woman. I am a\n"
     ]
    }
   ],
   "source": [
    "eos_id = tokenizer.encode(tokenizer.eos_token)[0]\n",
    "\n",
    "result = tokenizer(\"Once upon a time,\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))\n",
    "\n",
    "result = tokenizer(\"My name is Clara and I am\")\n",
    "input = result[\"input_ids\"]\n",
    "mask = result[\"attention_mask\"]\n",
    "input = pad_tokens(input, block_size, 0)\n",
    "mask = pad_tokens(mask, block_size, 0)\n",
    "input = torch.tensor([input], dtype=torch.int64).to(device)\n",
    "mask = torch.tensor([mask], dtype=torch.int64).to(device)\n",
    "\n",
    "result_token, result_len = generate_text(\n",
    "    model,\n",
    "    input,\n",
    "    mask,\n",
    "    eos_id,\n",
    "    pred_sequence_length=15)\n",
    "print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fb60b-c05d-4884-a9bc-92152c94c894",
   "metadata": {},
   "source": [
    "Now we generate text with our test dataset (5 rows).<br>\n",
    "As you can see below, it cannot output the completion well, because it's not still fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495728ef-fbe6-4953-a354-4b7a8bb88798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "name : Wildwood | Type : pub | food : Indian | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : Wildwood | Type : pub | food : Indian | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "Raja Indian Cuisine : Indian | price : Rs. 1,000 | menu : Indian | menu type : food | menu size :\n",
      "********** input **********\n",
      "name : Giraffe | Type : pub | food : Fast food | area : riverside | family friendly : yes | near : Rainbow Vegetarian Café\n",
      "\n",
      "********** result **********\n",
      "name : Giraffe | Type : pub | food : Fast food | area : riverside | family friendly : yes | near : Rainbow Vegetarian Café\n",
      "\n",
      ": Giraffe | Type : pub | food : Fast food | area : riverside | family friendly : yes | near : Rainbow Vegetarian Café\n",
      "********** input **********\n",
      "name : The Waterman | Type : pub | food : Italian | price : less than £ 20 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Waterman | Type : pub | food : Italian | price : less than £ 20 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "The Waterman is a pub in the heart of the city centre. It is a place where you can enjoy a good meal and drink a good\n",
      "********** input **********\n",
      "name : The Vaults | Type : pub | food : Italian | price : moderate | customer rating : 1 out of 5 | area : city centre | family friendly : no | near : Rainbow Vegetarian Café\n",
      "\n",
      "********** result **********\n",
      "name : The Vaults | Type : pub | food : Italian | price : moderate | customer rating : 1 out of 5 | area : city centre | family friendly : no | near : Rainbow Vegetarian Café\n",
      "\n",
      "The Vaults | Type : pub | food : Italian | price : moderate | customer rating : 1 out of 5 | area : city centre | family\n",
      "********** input **********\n",
      "name : The Vaults | Type : restaurant | food : French | price : less than £ 20 | area : riverside | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Vaults | Type : restaurant | food : French | price : less than £ 20 | area : riverside | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "The restaurant is located in the centre of the city. It is a small restaurant with a small menu. The menu is very simple and the food\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3138341-e01c-4fae-af78-c61e34967e92",
   "metadata": {},
   "source": [
    "## LoRA (Low-Rank Adaptation)\n",
    "\n",
    "Now we apply LoRA in our downloaded model.<br>\n",
    "For semantics of LoRA (Low-Rank Adaptation), see [01-finetune-opt-with-lora.ipynb](./01-finetune-opt-with-lora.ipynb).\n",
    "\n",
    "For the purpose of your learning, here I manually (from scratch) convert the current model into the model with LoRA.\n",
    "\n",
    "> Note : You can use ```PEFT``` package to be able to get LoRA model with a few lines of code. (Here I don't use this package.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296bdf2-129a-4278-8fe3-d08333ebf1df",
   "metadata": {},
   "source": [
    "Before changing our model, first we check the structure of our model. (See the following result in the cell.)\n",
    "\n",
    "As you can see below, you cannot find any linear layers in OpenAI's GPT-2 transformer, unlike [Meta's OPT transformer](./01-finetune-opt-with-lora.ipynb). Instead, you will find Conv1D (1D convolution) in transformer.<br>\n",
    "However, this Conv1D is not ```torch.nn.Conv1d``` and it's a custom layer defined for OpenAI GPT, which works same as a linear layer, but the weights are transposed. (See [this source code](https://github.com/huggingface/transformers/blob/main/src/transformers/pytorch_utils.py) for custom ```pytorch_utils.Conv1D``` implementation.)<br>\n",
    "This custom Conv1D layer (intrinsically, a linear layer) is used for MLP and getting key/value/query in GPT-2 transformer as follows.<br>\n",
    "(See [source code](https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py) for GPT-2 in Hugging Face tarnsformers.)\n",
    "\n",
    "- ```transformer.h.n.attn.c_attn``` : Layer to get key/value/query before processing attention.\n",
    "- ```transformer.h.n.attn.c_proj``` : Layer for projection after processing attention.\n",
    "- ```transformer.h.n.mlp.c_attn``` : MLP in GPT-2 is Linear(GeLU(Linear)). This is an inner Linear layer (custom Conv1D).\n",
    "- ```transformer.h.n.mlp.c_proj``` : MLP in GPT-2 is Linear(GeLU(Linear)). This is an outer Linear layer (custom Conv1D).\n",
    "\n",
    "In this example, we'll only convert ```transformer.h.n.attn.c_attn``` layers into LoRA layers.<br>\n",
    "The transformer in GPT-2 with 124M parameters has 12 layers and it then has total 12 layers (n=0,1, ... , 11) to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5acb8f62-791a-4fa4-b00c-2666cf34827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e7239-cb8a-46dd-815d-e48e7e49eea4",
   "metadata": {},
   "source": [
    "First we build custom linear layer with LoRA as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77889272-9a93-491b-93cb-b0bed5ce7cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class LoRA_Linear(nn.Module):\n",
    "    def __init__(self, weight, bias, lora_dim):\n",
    "        super(LoRA_Linear, self).__init__()\n",
    "\n",
    "        row, column = weight.shape\n",
    "\n",
    "        # restore Linear\n",
    "        if bias is None:\n",
    "            self.linear = nn.Linear(column, row, bias=False)\n",
    "            self.linear.load_state_dict({\"weight\": weight})\n",
    "        else:\n",
    "            self.linear = nn.Linear(column, row)\n",
    "            self.linear.load_state_dict({\"weight\": weight, \"bias\": bias})\n",
    "\n",
    "        # create LoRA weights (with initialization)\n",
    "        self.lora_right = nn.Parameter(torch.zeros(column, lora_dim))\n",
    "        nn.init.kaiming_uniform_(self.lora_right, a=math.sqrt(5))\n",
    "        self.lora_left = nn.Parameter(torch.zeros(lora_dim, row))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.linear(input)\n",
    "        y = input @ self.lora_right @ self.lora_left\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e2c9d-545e-4bd9-9b0f-eba3fe29a1de",
   "metadata": {},
   "source": [
    "Replace targeting linear layers with LoRA layers.<br>\n",
    "As I have mentioned above, custom Conv1D layer in GPT-2 is intrinsically equivalent to a linear layer, but the weights are transposed.\n",
    "\n",
    "> Note : According to the practice in [paper](https://arxiv.org/abs/2106.09685), LoRA is applied only to query and value projections with $r=4$.<br>\n",
    "> In this implementation, however, I'll apply LoRA to entire ```transformer.h.n.attn.c_attn``` layer, which is a projection for key, value, and query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf8a748-a3e3-45b8-9c64-252c56abe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_dim = 128\n",
    "\n",
    "# get target module name\n",
    "target_names = []\n",
    "for name, module in model.named_modules():\n",
    "    if \"attn.c_attn\" in name:\n",
    "        target_names.append(name)\n",
    "\n",
    "# replace each module with LoRA\n",
    "for name in target_names:\n",
    "    name_struct = name.split(\".\")\n",
    "    # get target module\n",
    "    module_list = [model]\n",
    "    for struct in name_struct:\n",
    "        module_list.append(getattr(module_list[-1], struct))\n",
    "    # build LoRA\n",
    "    lora = LoRA_Linear(\n",
    "        weight = torch.transpose(module_list[-1].weight, 0, 1),\n",
    "        bias = module_list[-1].bias,\n",
    "        lora_dim = lora_dim,\n",
    "    ).to(device)\n",
    "    # replace\n",
    "    module_list[-2].__setattr__(name_struct[-1], lora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae2df9-fae7-4ecc-8260-80e8e578d951",
   "metadata": {},
   "source": [
    "See how model is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf16b414-b973-40eb-be81-fd2aa3dde439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): LoRA_Linear(\n",
       "            (linear): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          )\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9099c08-f6a6-45f8-939b-cc3ed9415976",
   "metadata": {},
   "source": [
    "Finally, freeze all parameters except for LoRA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d06bba-955b-4806-8ff7-f217252e3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora_right\" in name or \"lora_left\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a4469-2827-4f30-9324-711a9feea1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do this when you run adapter fine-tuning on Hugging Face framework\n",
    "# model.gradient_checkpointing_enable()\n",
    "# model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c7d6f-6c50-4839-88a5-c851caab9ba2",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b875f-36cc-40b8-aaab-1efda68710f3",
   "metadata": {},
   "source": [
    "Now let's start to run fine-tuning.\n",
    "\n",
    "First we build optimizer as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb51298a-2d55-466c-a990-0ea08a247350",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=0.0002,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37db1a8-0053-4acc-94ce-89d87c78942e",
   "metadata": {},
   "source": [
    "In this example, we build linear scheduler for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f95bdf6-4498-4d40-90aa-1267d55f38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "num_epochs = 2\n",
    "num_warmup_steps = 500\n",
    "\n",
    "num_update_steps = math.ceil(len(dataloader) / batch_size / gradient_accumulation_steps)\n",
    "def _get_linear_schedule(current_step):\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    return max(0.0, float(num_update_steps * num_epochs - current_step) / float(max(1, num_update_steps * num_epochs - num_warmup_steps)))\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=_get_linear_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9e828-c4fb-493d-a6de-78e03dbf035e",
   "metadata": {},
   "source": [
    "Run fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3752481d-8ee8-4c43-b677-add136a2fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 42/42 - loss: 1.3620\n",
      "Epoch 2 42/42 - loss: 1.4432\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "if os.path.exists(\"loss.txt\"):\n",
    "    os.remove(\"loss.txt\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    model.train()\n",
    "    for i, (inputs, labels, masks) in enumerate(dataloader):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(\n",
    "                input_ids=inputs,\n",
    "                attention_mask=masks,\n",
    "            )\n",
    "            loss = F.cross_entropy(outputs.logits.transpose(1,2), labels)\n",
    "            loss.backward()\n",
    "            if ((i + 1) % gradient_accumulation_steps == 0) or \\\n",
    "               (i + 1 == len(dataloader)):\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            print(f\"Epoch {epoch+1} {math.ceil((i + 1) / batch_size / gradient_accumulation_steps)}/{num_update_steps} - loss: {loss.item() :2.4f}\", end=\"\\r\")\n",
    "\n",
    "        # record loss\n",
    "        with open(\"loss.txt\", \"a\") as f:\n",
    "            f.write(str(loss.item()))\n",
    "            f.write(\"\\n\")\n",
    "    print(\"\")\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), \"finetuned_gpt2.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83993d92-d7ed-4a07-8985-cc59bd4e4fef",
   "metadata": {},
   "source": [
    "> Note : Here we save LoRA-enabled model without any changes, but you can also merge the trained LoRA's parameters into the original model's weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc086e5-e93f-4264-a8fa-6428f844ac3c",
   "metadata": {},
   "source": [
    "Show loss transition in plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e37c5aee-38d4-4a2a-952c-4fd2bef41e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"loss.txt\")\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809bc9f-4ff6-46c3-9c43-08c6c2694a82",
   "metadata": {},
   "source": [
    "## Generate text with fine-tuned model\n",
    "\n",
    "Again we check results with our test dataset (5 rows).<br>\n",
    "As you can see below, it can output the completion very well, because it's fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29903cae-404e-4209-9c84-6c8a69609c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** input **********\n",
      "name : The Vaults | Type : pub | food : Italian | price : less than £ 20 | customer rating : low | area : city centre | family friendly : no | near : Rainbow Vegetarian Café\n",
      "\n",
      "********** result **********\n",
      "name : The Vaults | Type : pub | food : Italian | price : less than £ 20 | customer rating : low | area : city centre | family friendly : no | near : Rainbow Vegetarian Café\n",
      "The Vaults is a pub near the Rainbow Vegetarian Café in the city centre. It is not family friendly and has a low customer rating of less than\n",
      "********** input **********\n",
      "name : The Cricketers | Type : restaurant | customer rating : average | family friendly : yes | near : Café Sicilia\n",
      "\n",
      "********** result **********\n",
      "name : The Cricketers | Type : restaurant | customer rating : average | family friendly : yes | near : Café Sicilia\n",
      "The Cricketers is a restaurant near Café Sicilia. It is family friendly and has an average customer rating.<|endoftext|>\n",
      "********** input **********\n",
      "name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly : no | near : All Bar One\n",
      "\n",
      "********** result **********\n",
      "name : The Cricketers | Type : restaurant | food : Chinese | price : cheap | customer rating : average | area : city centre | family friendly : no | near : All Bar One\n",
      "The Cricketers is a restaurant located in the city centre near All Bar One. It is not family - friendly. It is located in the cheap\n",
      "********** input **********\n",
      "name : The Vaults | Type : pub | food : Japanese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Vaults | Type : pub | food : Japanese | price : cheap | customer rating : 5 out of 5 | area : city centre | family friendly : yes | near : Raja Indian Cuisine\n",
      "The Vaults is a cheap, family friendly pub located in the city centre near Raja Indian Cuisine.<|endoftext|>\n",
      "********** input **********\n",
      "name : The Wrestlers | Type : pub | food : Italian | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "\n",
      "********** result **********\n",
      "name : The Wrestlers | Type : pub | food : Italian | price : less than £ 20 | area : riverside | family friendly : no | near : Raja Indian Cuisine\n",
      "The Wrestlers is a pub near Raja Indian Cuisine in riverside. It is not family friendly.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test_formatted.jsonl\", lines=True)\n",
    "test_data = test_data[::2]  # because it's duplicated\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_data[\"context\"], [\"\"] * len(test_data[\"context\"]))),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "for i, (input, _, mask) in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(\"********** input **********\")\n",
    "    input_len = torch.sum(mask).cpu().numpy()\n",
    "    print(tokenizer.decode(input[0][:input_len]))\n",
    "    result_token, result_len = generate_text(\n",
    "        model,\n",
    "        input,\n",
    "        mask,\n",
    "        eos_id,\n",
    "        pred_sequence_length=30)\n",
    "    print(\"********** result **********\")\n",
    "    print(tokenizer.decode(result_token[0][:result_len]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c1dd3-4057-497a-83ae-f99b1883697e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
